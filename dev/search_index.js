var documenterSearchIndex = {"docs":
[{"location":"example/corpus/#Analyzing-a-text-corpus","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"","category":"section"},{"location":"example/corpus/#Summary","page":"Analyzing a text corpus","title":"Summary","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"We start with a corpus citable by CTS URN. In these examples, we'll work with a citable corpus of the five extant versions of the Gettysburg Address.  We will then construct an AnalyticalCorpus that matches this citable corpus with an orthography and a parser.  With this in hand, we can create a full, morphologically aware analysis of each token in the corpus with a single function call.","category":"page"},{"location":"example/corpus/#Load-the-source-corpus","page":"Analyzing a text corpus","title":"Load the source corpus","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"We can load the source data into the CitableTextCorpus model from a URL.  The corpus_cex function works on string data, so we will use standard Julia methods to load a String from the URL.","category":"page"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"using CitableBase, CitableCorpus\ncorpusurl = \"https://raw.githubusercontent.com/neelsmith/CitableCorpusAnalysis.jl/dev/test/data/gettysburg/gettysburgcorpus.cex\"\ncorpus = fromcex(corpusurl, CitableTextCorpus, UrlReader)\ntypeof(corpus)","category":"page"},{"location":"example/corpus/#Constructing-an-AnalyticalCorpus","page":"Analyzing a text corpus","title":"Constructing an AnalyticalCorpus","text":"","category":"section"},{"location":"example/corpus/#Orthography","page":"Analyzing a text corpus","title":"Orthography","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"The Orthography module includes a simple ASCII orthography that we can use with our Gettsyburg corpus.","category":"page"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"using Orthography\northography = simpleAscii()\ntypeof(orthography) |> supertype","category":"page"},{"location":"example/corpus/#Morphology","page":"Analyzing a text corpus","title":"Morphology","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"The CitableCorpusAnalysis module includes an implementation of the CitableParser abstraction that can parse tokens in the Gettysburg Address to their corresponding Penn treebank POS code.  (For details on how the parser was constructed, see the appendix to this documentation.)","category":"page"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"using CitableParserBuilder\nparser = CitableParserBuilder.gettysburgParser()\ntypeof(parser) |> supertype","category":"page"},{"location":"example/corpus/#The-analytical-corpus","page":"Analyzing a text corpus","title":"The analytical corpus","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"Our analytical corpus associates these three components.","category":"page"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"using CitableCorpusAnalysis\nacorpus = AnalyticalCorpus(corpus, orthography, parser)\ntypeof(acorpus)","category":"page"},{"location":"example/corpus/#The-analyses","page":"Analyzing a text corpus","title":"The analyses","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"The analyzecorpus function requires an AnalyticalCorpus as an argument. It first creates a tokenized edition, then analyses each token. It returns a Vector of AnalyzedTokens, where each CitablePassage is associated with a (possibly empty) Vector of Analysis objects.","category":"page"},{"location":"example/corpus/#Additional-arguments","page":"Analyzing a text corpus","title":"Additional arguments","text":"","category":"section"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"The analyzecorpus function allows an optional data parameter that will passed along to the parsing functions it applies.  In this example, the GettysburgParser can use a dictionary of analyses to get better performance, since it otherwise loads the entire dictionary for each individual parse.","category":"page"},{"location":"example/corpus/","page":"Analyzing a text corpus","title":"Analyzing a text corpus","text":"analyses = analyzecorpus(acorpus; data = parser.data)","category":"page"},{"location":"example/profiling/#Profiling-a-corpus","page":"Profiling a corpus","title":"Profiling a corpus","text":"","category":"section"},{"location":"example/profiling/#Using-a-Vector-of-AnalyzedTokens","page":"Profiling a corpus","title":"Using a Vector of AnalyzedTokens","text":"","category":"section"},{"location":"example/profiling/","page":"Profiling a corpus","title":"Profiling a corpus","text":"The analyzecorpus function yields a list of AnalyzedTokens.  We can derive metrics for our corpus from this list including:","category":"page"},{"location":"example/profiling/","page":"Profiling a corpus","title":"Profiling a corpus","text":"lexical metrics\nthe lexical ambiguity of the corpus\nthe lexical histogram of the corpus\nmeasures of the coverage of the parser for the corpus\nmorphological metrics\nthe morphological ambiguity of the corpus\nthe morphological histogram of the corpus","category":"page"},{"location":"example/topicmodeling/#Topic-modeling","page":"Topic modeling","title":"Topic modeling","text":"","category":"section"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"The lda_tm function creates a topic model for a citable corpus. It treats each citable passage as a document, and uses the lda function of the TextAnalysis package to create the model. The only required parameters are a citable corpus, and the number of topics to  create.  You can use the following optional parameters to tweak the settings of the underlying lda function:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"alpha is the TextAnalysis package's α. From its documentation: \"The hyperparameter for topic distribution per document. α<1 yields a sparse topic mixture for each document. α>1 yields a more uniform topic mixture for each document.\"\nbeta  is the TextAnalysis package's β. \"The hyperparameter for word distribution per topic. β<1 yields a sparse word mixture for each topic. β>1 yields a more uniform word mixture for each topic.\"\niters Number of iterations.\nstopwords List of terms to omit from the model.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"In addition, you can optionally supply a vector of string values to identify each document in the doclabels parameter.  By default, this parameter is an empty Vector; in that case, lda_tm uses the string value of each passage's URN to identify the topic modeling document.  Note that if you choose to supply a doclabels parameter, values must be unique, and the length of doclabels must equal the number of citable passages in the source citable corpus.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"The following example uses the famous corpus of State of the Union addresses from 1914 through 2009, included in a citable format in the test/data directory of this repository.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"using CitableBase, CitableCorpus\ncorpusurl = \"https://raw.githubusercontent.com/neelsmith/CitableCorpusAnalysis.jl/dev/test/data/sotu.cex\"\ncorpus = fromcex(corpusurl, CitableTextCorpus, UrlReader)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"In the same test/data directory, there is a brief stop-word list for this corpus.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"using Downloads\nstopurl = \"https://raw.githubusercontent.com/neelsmith/CitableCorpusAnalysis.jl/dev/test/data/stopwords-sotu.txt\"\nstopfile = Downloads.download(stopurl)\nstopwords = readlines(stopfile)\nrm(stopfile)\nlength(stopwords)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"We can now create a model for the corpus.  We'll  iterate 50 times and create 20 topics.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"using CitableCorpusAnalysis\ntm = lda_tm(corpus, 20; stopwords = stopwords, iters = 50)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"The resulting TopicModel object has four fields.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"terms List of terms in the model.\ndocids Identifiers for documents in the model.  This will be either the values provided in the doclabels parameter, or string values of each passage's URNs.\ntopic_terms The topic-term matrix (ϕ of the TextAnalysis packages lda output)\ntopic_docs The topic-document matrix (θ  of the TextAnalysis packages lda output)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"The following functions provide convenient access to several simple operations on these values.","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Number of topics computed (traditionally, k, equivalent to the second parameter provided to the lda_tm function):","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"k(tm)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"A labelling string for a given topic number composed from the most common terms in the topic:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"topiclabel(tm, 1)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"A labelling string for all topics in the model:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"topiclabels(tm)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Find string label and score for the top n scoring terms in a given topic:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"topterms(tm, 1; n = 5)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Index of a given term in the terms field:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"termindex(tm, \"et\")","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Index of a given document in the docids field:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":" documentindex(tm, \"urn:cts:latinLit:stoa1263.stoa001.hc:t.1\") ","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Scores of each topic for a given document:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"topicsfordoc(tm, 1)","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Label and score of the highest-scored topic for a given document:","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"topicfordoc(tm, 1) ","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"Function to label and score of all n highest-scoring topics for a given document is currently broken!","category":"page"},{"location":"example/topicmodeling/","page":"Topic modeling","title":"Topic modeling","text":"#topdocs(tm, 1; n = 5)","category":"page"},{"location":"#CitableCorpusAnalysis.jl","page":"Overview","title":"CitableCorpusAnalysis.jl","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Tokenize and analyze a citable text corpus.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"There are many ways to model a text corpus.  The CitableCorpusAnalysis module integrates two models from other Julia modules:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Corpus in TextAnalysis\nCitableTextCorpus in CitableCorpus","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"One application of this integration is to allow LDA topic modeling (from the TextAnalysis package) to operate on a CitableTextCorpus.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"CitableCorpusAnalysis.jl also introduces a further model, the AnalyticalCorpus.","category":"page"},{"location":"#Overview-of-an-analytical-corpus","page":"Overview","title":"Overview of an analytical corpus","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"An AnalyticalCorpus has three components:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"a citable corpus of texts (a CitableText.CitableTextCorpus)\nan orthographic system that can validate orthography and tokenize a citable text (an Orthography.OrthographicSystem)\na citable parser, that analyses citable tokens in terms of citable lexemes and morphological or other data (a CitableParserBuilder.CitableParser)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Functions working with an AnalyticalCorpus can tokenize a corpus, analyze its tokens with a CitableParser, and can apply the corpus analytical functions of a TextAnalysis.Corpus to any citable text content.","category":"page"},{"location":"#Example-pages","page":"Overview","title":"Example pages","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The following pages walk through examples using a small corpus comprising all the extant versions of the Gettysburg address.  We will tokenize it with a simple ASCII tokenizer included in the Orthography module, and will parse it with a custom GettysburgParser built for this demo. (Its construction is documented in the appendix to these pages, and illustrates one simple way to build an English-language parser by wrapping the Python NLTK POS tagger.)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using CitableCorpusAnalysis\nusing CitableCorpus, CitableBase\nusing Orthography\nusing CitableParserBuilder\n\n# Load a CitableCorpus from a URL:\nurl = \"https://raw.githubusercontent.com/neelsmith/CitableCorpusAnalysis.jl/dev/test/data/gettysburg/gettysburgcorpus.cex\"\ncorpus = fromcex(url,CitableTextCorpus,UrlReader)\n# Instantiate an orthographic system and parser\northography = Orthography.simpleAscii()\nparser = CitableParserBuilder.gettysburgParser()\nacorpus = AnalyticalCorpus(corpus, orthography, parser)\ntypeof(acorpus)","category":"page"},{"location":"example/models/#Using-different-models-of-a-text-corpus","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"","category":"section"},{"location":"example/models/#CitableTextCorpus","page":"Using different models of a text corpus","title":"CitableTextCorpus","text":"","category":"section"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"The base model of a text corpus is the CitableTextCorpus: a citable, human-readable series of text passages.  ","category":"page"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"using CitableBase, CitableCorpus\ncorpusurl = \"https://raw.githubusercontent.com/neelsmith/CitableCorpusAnalysis.jl/dev/test/data/gettysburg/gettysburgcorpus.cex\"\ncorpus = fromcex(corpusurl, CitableTextCorpus, UrlReader)","category":"page"},{"location":"example/models/#TextAnalysis.Corpus","page":"Using different models of a text corpus","title":"TextAnalysis.Corpus","text":"","category":"section"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"You can convert this to the Corpus  model of Julia's TextAnalysis module.","category":"page"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"using CitableCorpusAnalysis\nta_corp = tacorpus(corpus)","category":"page"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"The TextAnalysis module has a variety of functions for basic metrics on a text, and for corpora in English, includes more advanced tools for tokenizing, tagging for part of speech, and working with neural models.  See the documentation for TextAnalysis.Corpus.","category":"page"},{"location":"example/models/","page":"Using different models of a text corpus","title":"Using different models of a text corpus","text":"warning: Tokenization\nIf the assumptions of TextAnalysis (oriented towards English) are not appropriate for your corpus, you can sometimes work around this by preprocessing your original CitableCorpus.  E.g, by creating a tokenized corpus that takes account of a specified orthography, and using this as the source for a TextAnalysis.Corpus, you can protect your corpus from naive assumptions about tokenization.","category":"page"},{"location":"man/api/#API-Documentation","page":"API documentation","title":"API Documentation","text":"","category":"section"},{"location":"man/api/#Types","page":"API documentation","title":"Types","text":"","category":"section"},{"location":"man/api/","page":"API documentation","title":"API documentation","text":"AnalyticalCorpus","category":"page"},{"location":"man/api/#CitableCorpusAnalysis.AnalyticalCorpus","page":"API documentation","title":"CitableCorpusAnalysis.AnalyticalCorpus","text":"Essential components of an analytical corpus.\n\nIts contents must be citable, in a defined orthography, and tokens defined by that orthography must be parseable.\n\n\n\n\n\n","category":"type"},{"location":"man/api/#Exported-functions","page":"API documentation","title":"Exported functions","text":"","category":"section"},{"location":"man/api/","page":"API documentation","title":"API documentation","text":"tacorpus\ntalexicon\ndtmatrix","category":"page"},{"location":"man/api/#CitableCorpusAnalysis.tacorpus","page":"API documentation","title":"CitableCorpusAnalysis.tacorpus","text":"Create a TextAnalysis.Corpus from a CitableTextCorpus.\n\ntacorpus(c)\n\n\n\n\n\n\n","category":"function"},{"location":"man/api/#CitableCorpusAnalysis.talexicon","page":"API documentation","title":"CitableCorpusAnalysis.talexicon","text":"Create a lexicon (a Dict of tokens to counts) from a CitableTextCorpus using the lexicon function of the TextAnalysis module.\n\ntalexicon(c)\n\n\n\n\n\n\n","category":"function"},{"location":"man/api/#CitableCorpusAnalysis.dtmatrix","page":"API documentation","title":"CitableCorpusAnalysis.dtmatrix","text":"Creates the document-term matrix for a CitableTextCorpus in dense matrix  format.\n\ndtmatrix(c)\n\n\nNote that this relies on the dictionary created by TextAnalysis.lexicon().\n\n\n\n\n\n","category":"function"}]
}
